services:
  koalawiki:
    image: crpi-j9ha7sxwhatgtvj4.cn-shenzhen.personal.cr.aliyuncs.com/koala-ai/koala-wiki
    ports:
      - 8080:8080
    environment:
      - KOALAWIKI_REPOSITORIES=/repositories
      - TaskMaxSizePerUser=5 # 每个用户AI处理文档生成的最大数量
      - REPAIR_MERMAID=1 # 是否进行Mermaid修复，1修复，其余不修复
      - EmbeddingModel=text-embedding-3-small # Embedding模型
      - EmbeddingApiKey=  #为空则使用ChatApiKey
      - EmbeddingEndpoint= # 为空则使用Endpoint
      - ChatModel=DeepSeek-V3 # 必须要支持function的模型
      - AnalysisModel= # 分析模型，用于生成仓库目录结构，这个很重要，模型越强，生成的目录结构越好，为空则使用ChatModel
      - ChatApiKey= #您的APIkey
      - Endpoint=https://api.token-ai.cn/v1
    volumes:
      - ./repositories:/app/repositories
      - ./data:/data
    build:
      context: .
      dockerfile: src/KoalaWiki/Dockerfile
      
  koalawiki-web:
    image: crpi-j9ha7sxwhatgtvj4.cn-shenzhen.personal.cr.aliyuncs.com/koala-ai/koala-wiki-web
    ports:
      - 3000:3000
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
    build:
      context: .
      dockerfile: web/Dockerfile
      
  nginx:
    image: nginx:alpine
    ports:
      - 80:80
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - koalawiki
      - koalawiki-web

